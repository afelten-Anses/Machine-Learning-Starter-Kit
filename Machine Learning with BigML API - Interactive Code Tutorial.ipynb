{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BigML](http://bigml.com) is a service that makes Machine Learning accessible to the masses by abstracting away the complexities of creating predictive models from data. Here we will see how to use its API on the iris classification problem, which is the \"hello world\" of Machine Learning: you are shown a flower and you are to predict whether it is an iris setosa, an iris virginica or an iris versicolor.\n",
    "\n",
    "The way to do this is to take measurements of the flower and to run them through a predictive model built from an analysis of examples of flowers for which we knew the species.  The UCI repository has a [dataset of 150 iris examples](http://archive.ics.uci.edu/ml/datasets/Iris) which we'll use with BigML to create a model. Check out [this blog post for more explanations on how Machine Learning works (and when it fails to work)](http://louisdorard.com/blog/when-machine-learning-fails).\n",
    "\n",
    "# This page is interactive\n",
    "\n",
    "The following is an IPython notebook hosted on [Wakari](http://wakari.io) to show you how to use the BigML API to (1.) create a model and (2.) make predictions with the BigML API. IPython notebooks act as interactive web-based code tutorials. They are web pages in which there are blocks of code that you can edit and run. The code is run on the same server that serves the page (in this case it's run on Wakari's infrastructure) and the output is displayed on the page.\n",
    "\n",
    " > Click on the big green button above and create an account on Wakari (it's free).\n",
    "\n",
    "When you're back on this notebook, you'll be able to edit and run the blocks of code below (position your cursor inside them and press Shift+Enter). If you want more details on how IPython notebooks work, check out these [explanations on how to run code from within an iPython notebook](https://www.wakari.io/nb/url///wakari.io/static/notebooks/Part_1___Running_Code.ipynb).\n",
    "\n",
    "\n",
    "# 0. Initialize the BigML API\n",
    "\n",
    "First of all, you should create a free BigML account at [https://bigml.com/accounts/register/](https://bigml.com/accounts/register/) (it takes 2 minutes, literally).\n",
    "\n",
    "## Authentication variables\n",
    "\n",
    "Authentication is performed using your BigML username and API key, which can be found at https://bigml.com/account/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BIGML_USERNAME = '' # fill in your username between the quotes\n",
    "BIGML_API_KEY = '' # fill in your API key\n",
    "BIGML_AUTH = 'username=' + BIGML_USERNAME + ';api_key=' + BIGML_API_KEY # leave as it is\n",
    "print \"Authentication variables set!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API wrapper\n",
    "\n",
    "Let's first install the BigML API wrappers for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'bigml'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an _api_ object which will be used to communicate with the BigML API.\n",
    "\n",
    "Note that BigML has two ways of functioning: production mode or development mode. Here, we choose to use the latter since it's free!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "\n",
    "# Assuming you installed the BigML Python wrappers (with the 'pip install bigml' command, see above)\n",
    "# Assuming BIGML_USERNAME and BIGML_API_KEY were defined as shell environment variables\n",
    "# otherwise: api=BigML('your username here','your API key here',dev_mode=True)\n",
    "\n",
    "api=BigML(BIGML_USERNAME, BIGML_API_KEY, dev_mode=True) # use BigML in development mode for unlimited usage\n",
    "print \"Wrapper ready to use!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create a predictive model\n",
    "\n",
    "## Specify training data to use\n",
    "\n",
    "BigML makes a distinction between the origin of the data (the \"source\") and the actual data that's being used for training (the \"dataset\"). We first create a data source by specifying a csv file to use (hosted on Amazon S3 in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = api.create_source('s3://bigml-public/csv/iris.csv', {\"name\": \"Iris source\"})\n",
    "print \"'source' object created!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API calls are asynchronous, so we use _api.ok_ to make sure that the request has finished before we move on to the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.ok(source) # shows \"True\" when source has been created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source can be found on the BigML.com web interface at the following URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"https://bigml.com/dashboard/\"+str(source['resource'])+\"?\"+BIGML_AUTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the link doesn't work, check that you're logged in on the [BigML.com](http://www.bigml.com/) web interface and make sure that the toggle on the right is at \"development\" (and not \"production\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = api.create_dataset(source, {\"name\": \"Iris dataset\"})\n",
    "api.ok(dataset)\n",
    "print \"Dataset ready and available at https://bigml.com/dashboard/\"+str(dataset['resource'])+\"?\"+BIGML_AUTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you click on the outputted link above, it will take you to a histogram view of the data on the BigML dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn a model from the data\n",
    "\n",
    "This is done in just one command â€” there are no parameters to set whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = api.create_model(dataset)\n",
    "print \"'model' object created!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigML uses decision tree models. The tree that's been learnt from your data can be seen at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.ok(model) # making sure the model is ready\n",
    "print \"https://bigml.com/dashboard/\"+str(model['resource'])+\"?\"+BIGML_AUTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to predict the species of a new flower characterized by the following measurements (go on and edit the values if you want):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the strings below correspond to the headers of the iris.csv file we used to create the model\n",
    "new_input = {\"sepal length\": 4.8, \"sepal width\": 4.5, \"petal length\": 1.0, \"petal width\": 0.7}\n",
    "print \"'new_input' object created!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a prediction for this new input against the model we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = api.create_prediction(model, new_input)\n",
    "print \"Prediction: \",prediction['object']['output']\n",
    "print \"Confidence: \",prediction['object']['confidence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And more...\n",
    "\n",
    "This was just an overview of BigML's core functionalities. Check out [Bootstrapping Machine Learning](http://www.louisdorard.com/machine-learning-book) to learn more about Prediction APIs, how to apply ML to your domain, how to prepare your data CSV file and how to integrate predictions in your app or in your business.\n",
    "\n",
    "\n",
    "> Found this tutorial useful? [Vote on Hacker News!](https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fwww.wakari.io%2Fsharing%2Fbundle%2Flouisdorard%2FMachine%2520Learning%2520with%2520BigML%2520API%2520-%2520Interactive%2520Code%2520Tutorial&t=Machine%20Learning%20with%20BigML%20API%20-%20Interactive%20Code%20Tutorial)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
